<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Образ города</title>
    <link rel="stylesheet" type="text/css" href="mybulma/bulma-0.7.4%202/css/bulma.min.css">
    <link rel="stylesheet" type="text/css" href="mybulma/master.css">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
<div>
<nav class="navbar is-primary" role="navigation" aria-label="main navigation">
    <div id="navbarBasicExample" class="navbar-menu" style="margin-left: 100px; margin-right: 100px;">
        <div class="navbar-start">
            <a class="navbar-item" href="index.html">
                Главная
            </a>

            <a class="navbar-item" href="statistics.html">
                Статистика
            </a>

            <a class="navbar-item">
                О нас
            </a>
        </div>
    </div>
</nav>
<section class="hero is-primary is-medium is-fullheight-with-navbar" id="first_cont">
    <!-- Hero head: will stick at the top -->

    <!-- Hero content: will be in the middle -->
    <div class="hero-body">
        <div class="container has-text-centered">
            <h1 class="title">
                Образ города
            </h1>
            <h2 class="subtitle">
                Анализ эмоционального состояния в городе
            </h2>
        </div>
    </div>
</section>
<div class="container " style="height: 1500px">
    Цель
Создать веб-платформу, с помощью которой можно отслеживать настроение жителей города путем семантического анализа текста, хэштегов и эмоциональной окраски фотографии в социальных сетях.
Методика работы
	Схема работы:
		Парсинг данных из разных источников
		Обработка данных
		Проведение анализа
        Парсинг данных.
        Это первый этап. На этом этапе мы собираем данные из социальных сетей для анализа. В ходе разработки наша команда выбрала для начала соц. сеть Instagram. Для работы с социальной сетью была выбрана библиотека Instaloader (https://instaloader.github.io/). 
        Изначально, чтобы набрать данные, было собрано ~2000 постов. После этого парсинг был поставлен в фоновую задачу, чтобы постоянно обновлять данные (не более 100 постов по локации). Выполнение фоновых задач осуществляется через Celery. Данные сохраняются в PostgreSQL. На момент отправки документа имеется 2128 постов.
        В перспективе для сбора большего количества данных, можно подключить парсинг данных из соц. сети ВКонтакте через API (https://vk.com/dev/newsfeed.search). 
    
    Обработка данных.
        После сбора данные необходимо обработать. Для MVP было выбрано лишь одно направление - обработка текста. В дальнейшем будет проводится тематическое моделирование, а также анализ фотографий. 
    Обработка текста проходит в несколько этапов: форматирование текста через регулярное выражение, а после все слова в тексте приводятся в начальную форму (pymorphy2 (https://pymorphy2.readthedocs.io)). Это делается для наивной проверки на рекламные сообщения, т.е через стоп-слова. В дальнейшем, можно применить методы машинного обучения для определения спам сообщений. 
    Исходный текст проходит тональный анализ через NLTK (https://www.nltk.org/). Здесь возникает проблема с тем, что NLTK действует лишь для англоязычных текстов, однако это легко исправить, воспользовавшись API для работы с GoogleTranslator (https://cloud.google.com/translate/docs/apis). В связи с необходимостью его использования, для устранения ошибок при выполнении программы, используется функция удаления смайликов из текста, базирующаяся на библиотеке emoji (https://pypi.org/project/emoji/). Результат анализа записывается в базу данных.
    
    Отображение данных.
        После обработки данных, их необходимо предоставить пользователю платформы. 
    Для этого был выбран WEB фреймворк Django. Это обусловлено несколькими причинами: проект легко расширяется (поскольку представляется многомодульным, мы решили взять именно Django, а не Flask), интеграция с Celery (при добавлении новой локации, нужно просто добавить задачу, аргументом которой будет ID локации), легкость добавления представлений для работы API, основной язык разработки проекта - Python. 
    Для работы на клиентской стороне выбран JS (VueJS и библиотеки, для работы с картой, графиками).
    
</div>
</body>
</html>